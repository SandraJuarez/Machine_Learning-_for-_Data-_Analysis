{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax_metrics as jm\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from jax import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt# Switch off the cache \n",
    "from sklearn.metrics import confusion_matrix \n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenemos la matriz de pesos. Como tenemos la capa de input y una hidden, por eso tenemos dos pessos y dos bias\n",
    "\n",
    "    \n",
    "@staticmethod\n",
    "def random_layer_params(m, n, key, scale=2):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,1))\n",
    "\n",
    "    # Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "@staticmethod\n",
    "def one_hot(y, k_clases):\n",
    "    \"\"\"Create a one-hot encoding of y of size k_clases.\"\"\"\n",
    "    return jnp.array(y[:, None] == jnp.arange(k_clases))\n",
    "@staticmethod\n",
    "def activacion(x):\n",
    "    return jnp.maximum(0, x)#jnp.tanh(x)\n",
    "\n",
    "def softmax(Z):\n",
    "  A = jnp.exp(Z) / jnp.sum(jnp.exp(Z),axis=0)\n",
    "  return A\n",
    "\n",
    "def forward(params,x):\n",
    "    #input to hidden layers\n",
    "    activations=x\n",
    "    for w,b in params[:-1]:\n",
    "        outputs=jnp.dot(w,activations) + b #size -> (hidden,hidden anterior)\n",
    "        activations=activacion(outputs)\n",
    "        \n",
    "    #last hidden to output\n",
    "    #we use softmax for the last one\n",
    "    w_last, b_last = params[-1]\n",
    "    logits = jnp.dot(w_last, activations) + b_last\n",
    "    soft=softmax(logits) #size -> (classes,samples) ****\n",
    "    return soft\n",
    " \n",
    "def loss_function(params,x,y_hot):\n",
    "    soft=forward(params,x)\n",
    "    loss=jnp.mean(-y_hot*jnp.log(soft))\n",
    "    \n",
    "    return jnp.mean(-y_hot*jnp.log(soft))\n",
    "    \n",
    "@partial(jit, static_argnums=(0,))\n",
    "def update( params, x, y,learning_rate):\n",
    "    lr=learning_rate #learning rate\n",
    "    grads = grad(loss_function)(params, x, y)\n",
    "    \n",
    "    return [(w - lr * dw, b - lr* db)\n",
    "                    for (w, b), (dw, db) in zip(params, grads)]\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    #print(predictions, Y)\n",
    "    return jnp.sum(predictions == Y) / Y.size\n",
    "\n",
    "def dloss(params, x, y):\n",
    "        return grad(loss_function)(params, x, y)\n",
    "\n",
    "def prediction(soft): \n",
    "    return jnp.argmax(soft,axis=0)\n",
    "\n",
    "def get_pr(k_classes,samples,clases,y0,y_hat):\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    recall_list=[]\n",
    "    precision_list=[]\n",
    "    for k in range(k_classes):\n",
    "        for i in range (samples):\n",
    "            if y0[i]==clases[k] and y_hat[i]==clases[k]:\n",
    "                TP+=1\n",
    "            if y0[i]!=clases[k] and y_hat[i] == clases[k]:\n",
    "                FP+=1\n",
    "            if y0[i]==clases[k] and y_hat[i] != clases[k]:\n",
    "                FN+=1\n",
    "        if FP+TP!=0:\n",
    "            precision_list.append(TP/(TP+FP))\n",
    "        else:\n",
    "            precision_list.append(0)\n",
    "        if FN+TP!=0:\n",
    "            recall_list.append(TP/(TP+FN))\n",
    "        else:\n",
    "            recall_list.append(0)\n",
    "\n",
    "        \n",
    "        \n",
    "   \n",
    "    precision=sum(precision_list)/k_classes\n",
    "    recall=sum(recall_list)/k_classes\n",
    "    return precision,recall\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    #print(predictions, Y)\n",
    "    return jnp.sum(predictions == Y) / Y.size\n",
    "\n",
    "\n",
    "def modelo(sizes,key,max_steps,x,y,y_hot,learning_rate,k_clases,samples,clases,stop):\n",
    "    #y_hot=one_hot(y, k_clases)\n",
    "    #the initial parameters\n",
    "    params=init_network_params(sizes,random.PRNGKey(0))\n",
    "    print(params)\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    loss_list=[]\n",
    "    loss=10\n",
    "    \n",
    "    for i in range(max_steps):\n",
    "        old_loss=loss\n",
    "        loss=loss_function(params,x,y_hot)\n",
    "        g=dloss(params, x, y)\n",
    "        #print(g)\n",
    "        params=update(params, x, y_hot,learning_rate)\n",
    "        if i%100==0:\n",
    "            soft=forward(params,x)\n",
    "            y_hat=prediction(soft)\n",
    "            ac=get_accuracy(y_hat, y)\n",
    "            precision,recall=get_pr(k_clases,samples,clases,y,y_hat)\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            print(loss,i,precision,recall,ac)\n",
    "        if  jnp.abs(loss-old_loss)<stop:\n",
    "            break\n",
    "        #print(i,params)\n",
    "        #print(loss)\n",
    "    \n",
    "        \n",
    "    return loss\n",
    "\n",
    "def graficar_pr(recall_list,precision_list):\n",
    "    plt.style.use('rose-pine')\n",
    "    plt.plot(recall_list,precision_list,color='#fb9f9f',marker='*')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.show()\n",
    "\n",
    "def graficar_rc(loss_list):\n",
    "    plt.style.use('rose-pine')\n",
    "    plt.plot(loss_list,color='#fb9f9f')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Rate of Convergency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0\n",
      " 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 0\n",
      " 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0]\n",
      "y\n",
      "0\n",
      "1\n",
      "(2, 200)\n"
     ]
    }
   ],
   "source": [
    "#before trying with MNIST lets try with something simpller\n",
    "import sklearn.datasets\n",
    "x,y=sklearn.datasets.make_moons(200,noise=0.15) #x are inputs and y are the expected labels\n",
    "print(y)\n",
    "x=jnp.transpose(x) #because we wrote the equations thinking that sizeX=(features,samples)\n",
    "y=jnp.transpose(y)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(y,columns=['y'])\n",
    "renglones=df['y'].shape[0]\n",
    "df_categorical=df[['y']]\n",
    "columnas=df_categorical.shape[1]\n",
    "one_hot=np.zeros(renglones)\n",
    "\n",
    "col=0\n",
    "df2=pd.DataFrame()\n",
    "df3=pd.DataFrame()\n",
    "df3.insert(0,'1',one_hot)\n",
    "for k in range(0,columnas):\n",
    "    name=df_categorical.columns[k]\n",
    "    print(name)\n",
    "    lista=[]\n",
    "    lista=df_categorical[name].values.tolist()\n",
    "    clases=df_categorical[name].unique() #un array de las distintas clases\n",
    "    size_clases=len(clases)\n",
    "    \n",
    "    \n",
    "    for i in range(size_clases):\n",
    "        clase=clases[i]\n",
    "        print(clase)\n",
    "\n",
    "        for j in range(0,renglones):\n",
    "            if lista[j]==clase:\n",
    "                one_hot[j]=1  \n",
    "        \n",
    "        df2.insert(i,clase,one_hot)\n",
    "        \n",
    "        one_hot=np.zeros(renglones)\n",
    "    df3=df3.join(df2)\n",
    "    df2=pd.DataFrame()\n",
    "del df3[df3.columns[0]]\n",
    "y_hot=df3.to_numpy()\n",
    "#\n",
    "y_hot=jnp.transpose(y_hot)\n",
    "print(y_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[(DeviceArray([[-0.82923746, -1.146248  ],\n",
      "             [-1.170297  ,  1.1766202 ],\n",
      "             [ 1.3146174 ,  2.3568673 ]], dtype=float32), DeviceArray([[-0.5948747],\n",
      "             [ 5.230382 ],\n",
      "             [-0.0607711]], dtype=float32)), (DeviceArray([[ 0.08676989,  0.6301467 , -1.4263141 ],\n",
      "             [ 1.6186938 ,  0.04880301, -1.0032021 ],\n",
      "             [-2.0201273 ,  0.25526375, -2.33574   ],\n",
      "             [ 4.728775  ,  2.3069553 , -0.6993406 ]], dtype=float32), DeviceArray([[-1.7650905 ],\n",
      "             [-0.20067427],\n",
      "             [-0.61008555],\n",
      "             [-2.3439033 ]], dtype=float32)), (DeviceArray([[ 1.1595801 ,  3.2079782 ,  1.6459509 , -1.0763928 ],\n",
      "             [-0.09025478, -3.2137861 ,  1.0516778 , -0.28516877]],            dtype=float32), DeviceArray([[4.5517006],\n",
      "             [1.2412996]], dtype=float32))]\n",
      "1.0844892 0 0.5 0.75 0.5\n",
      "0.32005876 100 0.6821428571428572 0.575 0.65\n",
      "0.12938456 200 0.8991019417475729 0.9125000000000001 0.905\n",
      "0.12633243 300 0.8991019417475729 0.9125000000000001 0.905\n",
      "0.12560591 400 0.8991019417475729 0.9125000000000001 0.905\n",
      "0.12533008 500 0.8991019417475729 0.9125000000000001 0.905\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m clases\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m])\n\u001b[0;32m     10\u001b[0m stop\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m\n\u001b[1;32m---> 11\u001b[0m modelo(sizes,key,max_steps,x,y,y_hot,learning_rate,k_clases,samples,clases,stop)\n",
      "Cell \u001b[1;32mIn[11], line 125\u001b[0m, in \u001b[0;36mmodelo\u001b[1;34m(sizes, key, max_steps, x, y, y_hot, learning_rate, k_clases, samples, clases, stop)\u001b[0m\n\u001b[0;32m    123\u001b[0m y_hat\u001b[39m=\u001b[39mprediction(soft)\n\u001b[0;32m    124\u001b[0m ac\u001b[39m=\u001b[39mget_accuracy(y_hat, y)\n\u001b[1;32m--> 125\u001b[0m precision,recall\u001b[39m=\u001b[39mget_pr(k_clases,samples,clases,y,y_hat)\n\u001b[0;32m    126\u001b[0m precision_list\u001b[39m.\u001b[39mappend(precision)\n\u001b[0;32m    127\u001b[0m recall_list\u001b[39m.\u001b[39mappend(recall)\n",
      "Cell \u001b[1;32mIn[11], line 75\u001b[0m, in \u001b[0;36mget_pr\u001b[1;34m(k_classes, samples, clases, y0, y_hat)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m y0[i]\u001b[39m!=\u001b[39mclases[k] \u001b[39mand\u001b[39;00m y_hat[i] \u001b[39m==\u001b[39m clases[k]:\n\u001b[0;32m     74\u001b[0m         FP\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mif\u001b[39;00m y0[i]\u001b[39m==\u001b[39mclases[k] \u001b[39mand\u001b[39;00m y_hat[i] \u001b[39m!=\u001b[39m clases[k]:\n\u001b[0;32m     76\u001b[0m         FN\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m FP\u001b[39m+\u001b[39mTP\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:3570\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[1;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[0;32m   3567\u001b[0m   \u001b[39mreturn\u001b[39;00m _getslice(arr, start, stop)\n\u001b[0;32m   3569\u001b[0m treedef, static_idx, dynamic_idx \u001b[39m=\u001b[39m _split_index_for_jit(idx, arr\u001b[39m.\u001b[39mshape)\n\u001b[1;32m-> 3570\u001b[0m \u001b[39mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m   3571\u001b[0m                unique_indices, mode, fill_value)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:3579\u001b[0m, in \u001b[0;36m_gather\u001b[1;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[0;32m   3576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m   3577\u001b[0m             unique_indices, mode, fill_value):\n\u001b[0;32m   3578\u001b[0m   idx \u001b[39m=\u001b[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[1;32m-> 3579\u001b[0m   indexer \u001b[39m=\u001b[39m _index_to_gather(shape(arr), idx)  \u001b[39m# shared with _scatter_update\u001b[39;00m\n\u001b[0;32m   3580\u001b[0m   y \u001b[39m=\u001b[39m arr\n\u001b[0;32m   3582\u001b[0m   \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:3779\u001b[0m, in \u001b[0;36m_index_to_gather\u001b[1;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[0;32m   3776\u001b[0m \u001b[39mif\u001b[39;00m core\u001b[39m.\u001b[39msymbolic_equal_dim(x_shape[x_axis], \u001b[39m0\u001b[39m):\n\u001b[0;32m   3777\u001b[0m   \u001b[39m# XLA gives error when indexing into an axis of size 0\u001b[39;00m\n\u001b[0;32m   3778\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex is out of bounds for axis \u001b[39m\u001b[39m{\u001b[39;00mx_axis\u001b[39m}\u001b[39;00m\u001b[39m with size 0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 3779\u001b[0m i \u001b[39m=\u001b[39m _normalize_index(i, x_shape[x_axis]) \u001b[39mif\u001b[39;00m normalize_indices \u001b[39melse\u001b[39;00m i\n\u001b[0;32m   3780\u001b[0m i \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39mconvert_element_type(i, index_dtype)\n\u001b[0;32m   3781\u001b[0m gather_indices\u001b[39m.\u001b[39mappend((i, \u001b[39mlen\u001b[39m(gather_indices_shape)))\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:3453\u001b[0m, in \u001b[0;36m_normalize_index\u001b[1;34m(index, axis_size)\u001b[0m\n\u001b[0;32m   3449\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3450\u001b[0m   axis_size_val \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39mconvert_element_type(core\u001b[39m.\u001b[39mdimension_as_value(axis_size),\n\u001b[0;32m   3451\u001b[0m                                            _dtype(index))\n\u001b[0;32m   3452\u001b[0m \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mselect(\n\u001b[1;32m-> 3453\u001b[0m   lax\u001b[39m.\u001b[39;49mlt(index, _lax_const(index, \u001b[39m0\u001b[39;49m)),\n\u001b[0;32m   3454\u001b[0m   lax\u001b[39m.\u001b[39madd(index, axis_size_val),\n\u001b[0;32m   3455\u001b[0m   index)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\lax\\lax.py:468\u001b[0m, in \u001b[0;36mlt\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlt\u001b[39m(x: Array, y: Array) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[0;32m    467\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Elementwise less-than: :math:`x < y`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 468\u001b[0m   \u001b[39mreturn\u001b[39;00m lt_p\u001b[39m.\u001b[39;49mbind(x, y)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\core.py:327\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m    325\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[0;32m    326\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[1;32m--> 327\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\core.py:330\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 330\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[0;32m    331\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\core.py:680\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[1;32m--> 680\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39mimpl(\u001b[39m*\u001b[39mtracers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\dispatch.py:101\u001b[0m, in \u001b[0;36mapply_primitive\u001b[1;34m(prim, *args, **params)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m compiled_fun \u001b[39m=\u001b[39m xla_primitive_callable(prim, \u001b[39m*\u001b[39munsafe_map(arg_spec, args),\n\u001b[0;32m    100\u001b[0m                                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fun(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\dispatch.py:167\u001b[0m, in \u001b[0;36mxla_primitive_callable.<locals>.<lambda>\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    164\u001b[0m compiled \u001b[39m=\u001b[39m _xla_callable_uncached(lu\u001b[39m.\u001b[39mwrap_init(prim_fun), device, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    165\u001b[0m                                   prim\u001b[39m.\u001b[39mname, donated_invars, \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39marg_specs)\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prim\u001b[39m.\u001b[39mmultiple_results:\n\u001b[1;32m--> 167\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: compiled(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m   \u001b[39mreturn\u001b[39;00m compiled\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\dispatch.py:712\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[1;34m(name, compiled, input_handler, output_buffer_counts, result_handler, has_unordered_effects, ordered_effects, kept_var_idx, *args)\u001b[0m\n\u001b[0;32m    710\u001b[0m device, \u001b[39m=\u001b[39m compiled\u001b[39m.\u001b[39mlocal_devices()\n\u001b[0;32m    711\u001b[0m args, env \u001b[39m=\u001b[39m input_handler(args) \u001b[39mif\u001b[39;00m input_handler \u001b[39melse\u001b[39;00m (args, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 712\u001b[0m in_flat \u001b[39m=\u001b[39m flatten(device_put(x, device) \u001b[39mfor\u001b[39;49;00m i, x \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(args)\n\u001b[0;32m    713\u001b[0m                   \u001b[39mif\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m kept_var_idx)\n\u001b[0;32m    714\u001b[0m \u001b[39mif\u001b[39;00m has_unordered_effects \u001b[39mor\u001b[39;00m ordered_effects:\n\u001b[0;32m    715\u001b[0m   in_flat, token_handler \u001b[39m=\u001b[39m _add_tokens(has_unordered_effects, ordered_effects,\n\u001b[0;32m    716\u001b[0m                                        device, in_flat)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\util.py:111\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(xs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcatenate\u001b[39m(xs: Iterable[Sequence[T]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[T]:\n\u001b[0;32m    110\u001b[0m   \u001b[39m\"\"\"Concatenates/flattens a list of lists.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(it\u001b[39m.\u001b[39;49mchain\u001b[39m.\u001b[39;49mfrom_iterable(xs))\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\dispatch.py:712\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    710\u001b[0m device, \u001b[39m=\u001b[39m compiled\u001b[39m.\u001b[39mlocal_devices()\n\u001b[0;32m    711\u001b[0m args, env \u001b[39m=\u001b[39m input_handler(args) \u001b[39mif\u001b[39;00m input_handler \u001b[39melse\u001b[39;00m (args, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 712\u001b[0m in_flat \u001b[39m=\u001b[39m flatten(device_put(x, device) \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(args)\n\u001b[0;32m    713\u001b[0m                   \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m kept_var_idx)\n\u001b[0;32m    714\u001b[0m \u001b[39mif\u001b[39;00m has_unordered_effects \u001b[39mor\u001b[39;00m ordered_effects:\n\u001b[0;32m    715\u001b[0m   in_flat, token_handler \u001b[39m=\u001b[39m _add_tokens(has_unordered_effects, ordered_effects,\n\u001b[0;32m    716\u001b[0m                                        device, in_flat)\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\dispatch.py:978\u001b[0m, in \u001b[0;36mdevice_put\u001b[1;34m(x, device)\u001b[0m\n\u001b[0;32m    976\u001b[0m x \u001b[39m=\u001b[39m xla\u001b[39m.\u001b[39mcanonicalize_dtype(x)\n\u001b[0;32m    977\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 978\u001b[0m   \u001b[39mreturn\u001b[39;00m device_put_handlers[\u001b[39mtype\u001b[39;49m(x)](x, device)\n\u001b[0;32m    979\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    980\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo device_put handler for type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\52333\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\dispatch.py:989\u001b[0m, in \u001b[0;36m_device_put_array\u001b[1;34m(x, device)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mfloat0:\n\u001b[0;32m    988\u001b[0m   x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(x\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdtype(\u001b[39mbool\u001b[39m))\n\u001b[1;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m (backend\u001b[39m.\u001b[39;49mbuffer_from_pyval(x, device),)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sizes=[2,3,4,2]\n",
    "print(len(sizes))\n",
    "\n",
    "max_steps=10000\n",
    "key=2\n",
    "learning_rate=0.28\n",
    "k_clases=2\n",
    "samples=200\n",
    "clases=jnp.array([0,1])\n",
    "stop=0.00001\n",
    "modelo(sizes,key,max_steps,x,y,y_hot,learning_rate,k_clases,samples,clases,stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
